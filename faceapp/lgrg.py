import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
from sklearn.inspection import DecisionBoundaryDisplay
from sklearn.model_selection import GridSearchCV

x=np.array([
[0.16116463918626645, 0.2856499094445396, 0.04611437801429019, 0.4603167261063116, 0.44459404421491244],
[0.7265717597430921, 0.7873201123883696, 0.11715406942004658, 0.7670567696617434, 0.8187045279446836],
[1.0014431218396442, 0.7984556589881048, 0.09720927728563211, 0.955411973744662, 0.9098194550568708],
[0.12022387712162552, 0.07165212430388668, 0.030457572662130783, 0.2032689573415407, 0.18072936892775326],
[0.4222723686253702, 0.5325226185035392, 0.0780939303847219, 0.56904794481781, 0.8210004700257902],
[0.26549111278228865, 0.21915645722896682, 0.04313654989498261, 0.4153929877966458, 0.11264722546656425],
[0.3638688064615728, 0.5729436007543611, 0.075927193767237, 0.5280510165306893, 0.6261591712232548],
[0.4254996837883209, 0.3444540812350937, 0.06165305904501428, 0.6488138976134438, 0.5444836539953808],
[0.8944050199927593, 0.8104958757327774, 0.10944298496126026, 0.9504548230941294, 0.9092214104826369],
[1.1102230246251565, 2.220446049250313, 0.0, 0.0, 1.1102230246251565],
[0.0, 0.0, 0.0, 0.0, -2.220446049250313],
[0.5004747458160557, 0.530685562249086, 0.08105293736630159, 0.6976363819749044, 0.6063214979106135],
[0.8399936275527042, 0.8430585928083556, 0.081606119677751, 0.8672555359635896, 0.9928480770629307],
[0.17683227593157658, 0.1069822959167126, 0.05393604831668419, 0.3678162732192434, 0.32444413560128804],
[0.763696134338687, 0.6287598096868698, 0.0779189869266893, 0.8095531551413213, 0.9738360421879856],
[0.2950832161741539, 0.3738956909861354, 0.074384488176918, 0.6492309456897121, 0.06890337028323179],
[0.5723304366894398, 0.5842951263211085, 0.06238999921928723, 0.7058569960726748, 0.7612007185789019],
[0.11022314506165365, 0.1798655810291332, 0.03904483758038768, 0.3918480401693317, 0.31656053425956776],
[0.619071770945466, 0.5066504896954795, 0.08755295649935013, 0.6922668172461737, 0.7932967323140289],
[0.3200116579794843, 0.3960798899069812, 0.07155115439045423, 0.6056344359338028, 0.4630478350863487],
[0.8201126786161679, 0.7842664922821377, 0.044715266827002, 0.9132108526851077, 0.7251878560780747],
[0.2532104487633815, 0.204384113124492, 0.03984265156620648, 0.3793356291075559, 0.36569911212695405],
[0.45467457807346356, 0.6646681165262434, 0.07267528627655051, 0.7398664662393766, 0.6243489956901895],
[0.47622241972426427, 0.6966493143785264, 0.10211562025348786, 0.7766181394478007, 0.8879550419036724],
[0.3997330824980593, 0.35264234475646006, 0.05360206545292501, 0.5466531293131144, 0.4924368389877425],
[0.9911974163646415, 0.8856669360998115, 0.13482626794483787, 0.9703353448892339, 1.0118434271144205],
[0.38776599186450234, 0.36379919304791764, 0.0572360900198855, 0.6093748645722344, 0.6466700559112111],
[0.4136353524268137, 0.4043086066744789, 0.05323202089367329, 0.5727775617310368, 0.6826506282031806],
[0.729058787140521, 0.6768896824406074, 0.11258733852760494, 0.7025778510085885, 0.6937223272204265],
[0.31818042962184734, 0.30438950406198717, 0.06069815467404549, 0.5940960689815474, 0.5574609660177361],
[0.7788307185453469, 0.7819521499961041, 0.12248829968762676, 0.8514852736678094, 0.6601682174944077],
[0.2773724598045795, 0.37491334998771075, 0.03998283580540141, 0.5898536766708554, 0.4442132721738299],
[0.4803253158836106, 0.4551162263112536, 0.0809679160688711, 0.7414184125554923, 0.7057266659013395],
[0.19287071880113704, 0.2356575577795973, 0.0366201055274199, 0.3799756619589094, 0.2244972271824185],
[0.5533793440459529, 0.527734236926099, 0.07186253492310901, 0.6671024458146297, 0.7730906861933822],
[0.19616657964586126, 0.35036487386128545, 0.054312808705958227, 0.5098567836356751, 0.5363064049888029],
[0.8302921985176704, 0.9480119974431314, 0.16027581693964787, 0.8574522652142123, 0.9523538752124614],
[0.3046607963267941, 0.23102031373206044, 0.05644194395110114, 0.540377189495751, 0.4505080883992765],
[0.5626496567117603, 0.5783542518641303, 0.10353592585988325, 0.9048022826280695, 0.8482950843665135],
[0.510851866529406, 0.4053306242953919, 0.06574254127921364, 0.7435466859439932, 0.5473266070318504],
[0.6891270628195979, 0.7013611962998045, 0.0966760025212745, 0.7683325633921515, 0.848322069280452],
[0.46487487081797585, 0.33277927480740976, 0.04641550658142912, 0.4696121473311755, 0.5346745483788319],
[0.4159510457985025, 1.0265046730056466, 0.12432461700800213, 0.923076873362793, 0.938390487144106],
[0.20919114430501395, 0.2454803887660303, 0.05972794252243119, 0.34537090697775696, 0.5235525652055741],
[0.30694839771739835, 0.34606865604979176, 0.040357271829409846, 0.7447701022791298, 0.7186172285679868],
[0.24431567005334165, 0.3524289978494065, 0.07451828031344276, 0.5688448800720278, 0.430073869245556],
[0.6679805267075178, 0.6419265552373172, 0.08619539537102905, 0.8396553533883303, 0.9271214342696238],
[0.278594530456874, 0.31011758377434384, 0.03140855384389829, 0.47198311548689986, 0.0791301465178944],
[0.41352853272272183, 0.3986161472798949, 0.06831603022841648, 0.49956836703813956, 0.5684922982948415],
[0.36141913109113644, 0.2889804180901221, 0.05507369825546382, 0.6002447833167234, 0.4182647726934531],
[0.3492822765608593, 0.44253263620712835, 0.06934855810751306, 0.6232638557600527, 0.6829685874047711],
[0.18273497013108242, 0.21714660200490377, 0.0361882276970259, 0.47412063307896346, 0.4349583816697655],
[0.7604188356019461, 0.7300260399015149, 0.09696084290139906, 0.8278010905932659, 0.7628828438882705],
[0.091188426300541, 0.0035493534516732, 0.033904984309681474, 0.19177324734855195, 0.013395117383651733],
[0.314269499719236, 0.3996605698785678, 0.05914292807983046, 0.5678911826493165, 0.5444411906197406],
[0.2133802135384214, 0.2787402737042688, 0.03361345158184459, 0.3368853089367434, 0.3419942586113859],
[0.6179304882189447, 0.5455064808505649, 0.07360941699600831, 0.7769844932385224, 0.7752663216023551],
[0.15547136204609935, 0.19280346162062112, 0.05892670088829133, 0.4222644308670934, 0.46348492026718857],
[0.8125960537327374, 0.596747317285335, 0.067489111621159, 0.7188098118781858, 0.8656336284309863],
[0.07511038367097211, 0.09208849095673122, 0.026324519882651498, 0.2212804934234951, 0.2155365199122492],
[0.5525068402440229, 0.48895388252030014, 0.06389984240717494, 0.6257360969953295, 0.9158278167263494],
[0.19100310582194957, 0.1937041907394501, 0.029827141409510705, 0.38095836478623235, 0.1748002034370607],
[0.6438930426324991, 0.4856671219656332, 0.07334889415276946, 0.7451380940978344, 0.772873519109253],
[0.33116710385606263, 0.30800424576172414, 0.05254243414555837, 0.571830273110381, 0.4898984240618839],
[0.7047291289511894, 0.5462976293402557, 0.08088190109807891, 0.8129043448017665, 0.8813115492406179],
[0.24949527390009163, 0.20287791129766886, 0.01753917326861376, 0.515157766438596, 0.2156633459331294],
[0.6293731494607085, 0.6622481647136372, 0.05700738934189642, 0.8643829341842257, 0.9999648062801566],
[0.24949527390009163, 0.20287791129766886, 0.01753917326861376, 0.515157766438596, 0.2156633459331294],
[0.975930915954818, 0.866239005607803, 0.09778216032357101, 0.8474317273130695, 1.128893787538224],
[0.1463464626757589, 0.12666309926957287, 0.021186055447507735, 0.3656245249162906, 0.26577897372278203],
[0.7075269328323538, 0.8156487066444352, 0.058844363900964036, 0.7815105061442209, 0.7754837673229789],
[0.36259019491255073, 0.3785188792840589, 0.040160348917386623, 0.40425912978647593, 0.4302309424874554],
[0.429426031888294, 0.451069397494105, 0.03674091310941441, 0.6518102600924321, 0.6589069034329351],
[0.6159986111939264, 0.8737312166615315, 0.09430644576219782, 0.8734158325888506, 0.9629525892575466],
[0.873933849825248, 0.8195553906707195, 0.06293800015434337, 0.8861379189478462, 0.8174834210719688],
[0.2850424490545451, 0.3899302108723902, 0.041170844012465735, 0.7226220936265317, 0.49332379592162856],
[1.170616888892544, 0.9665291404031723, 0.12393608146845547, 0.9465446180496231, 0.9940668922238541],
[0.34582555488928757, 0.28705879232431986, 0.04306279513113065, 0.7747586434206272, 0.5017681613458838],
[0.7447447499171556, 0.8028555861565345, 0.09111383344034196, 0.8294747984263942, 0.8482700799651766],
[0.37647179026707267, 0.3437093761825941, 0.057360854659195604, 0.5757264886420188, 0.454725097372771],
[0.9577375396768198, 1.086036014740929, 0.14259712517982914, 0.9293668234723809, 0.9698665805217338],
[0.32206477303656966, 0.326989395864139, 0.06936699745636998, 0.49121742770974364, 0.5673634709263852],
[0.7539472108109114, 0.8275673723345853, 0.10857898372482577, 0.7759704505859318, 0.7551639975652518],
[0.2633524990661108, 0.21303388885189478, 0.02819936195467787, 0.28681926936855806, 0.22917687313526125],
[0.5974621376193399, 0.6321244443208495, 0.08956243664422292, 0.8026665126698574, 0.9356853112471998],
[0.129723520576014, 0.12352922116086185, 0.013236992877989961, 0.27275631862262784, 0.2152837315169439],
[0.8368877477902125, 0.7988098225137144, 0.0829476282423256, 0.8363836197738312, 0.9792810294780387],
[0.3486032672352186, 0.4947060434434176, 0.042689546743794105, 0.6527898291610481, 0.4130823686448729],
[0.7566723377138748, 0.9191557142399951, 0.10624230059423023, 0.7746934735596729, 0.940480701808647],
[0.17832989267768917, 0.3063738475924329, 0.06931961715598345, 0.7205748301578858, 0.38855421168795656],
[0.7775424457845714, 0.925883306754056, 0.08605707634376192, 0.8500397159739868, 0.9540821943493237],
[0.1963806136780799, 0.20663250632039154, 0.043428017274735, 0.29457113915573796, 0.38124723601581956],
[0.69954729951086, 0.7860345188996702, 0.09592403857917542, 0.8646873306162912, 0.7084447022101279],
[0.3167740659698248, 0.22203862850155465, 0.043982995212130005, 0.5221281734719952, 0.4915871092050831],
[1.0350545618897269, 1.0829519858029701, 0.09291262634505826, 0.9104345733996999, 0.9719465382140265],
[0.29999885386117686, 0.4859080322048742, 0.036025391099641424, 0.5330169873558471, 0.5129637607061639],
[0.7729809132748365, 1.0095710532935718, 0.09200023734791607, 0.9277584787204525, 0.9527884976189569],
[0.19764231135508448, 0.26237355433035536, 0.05493299709549093, 0.41724309223496325, 0.37831939579410223],
[0.6438275369126727, 0.7414663524203893, 0.0934691061849352, 0.8534437548017504, 0.7246362706033815],
[0.1176796334400948, 0.12226283569507834, 0.02054791652796939, 0.28258309265267423, 0.3071037370347446],
[0.8981612270259203, 0.7379886992025693, 0.06310459933021306, 0.8285185203223812, 0.8605767023445926],
[0.21354364274604598, 0.29344982750168647, 0.047059792667367706, 0.3979652070334354, 0.3434128119115947],
[0.9347439623006402, 0.8976098231423224, 0.0955602622321734, 0.9446532092081162, 0.9584465831062241],
[0.23868645385236953, 0.2533044643593797, 0.05816024973347067, 0.6491142005455748, 0.3635537414013492],
[0.7576887169263749, 0.9637485276696486, 0.12936062110940227, 0.8421355945013637, 0.885026068848623],
[0.22202842468406148, 0.25408744988735643, 0.07574458732085299, 0.6027197373718971, 0.38452390732121344],
[0.7121238331017596, 0.8333966618342428, 0.11097774117458381, 0.8389463826980355, 0.7685621570396742],
[0.17447281162924433, 0.14607851444581998, 0.024084703361151427, 0.3467430995334271, 0.2781743830430432],
[0.6760500955711144, 0.6235466993735087, 0.05129594997607956, 0.8320265190942282, 0.7013152488525538],
[0.29049820546480354, 0.21476336270617757, 0.0582850862919041, 0.5272083959629665, 0.30771877702929384],
[1.0888091850446537, 0.8584430595041108, 0.11620840171498481, 0.8557252099017697, 0.9192270620398776],
[0.24682247992149897, 0.20421427904895695, 0.045121323945605196, 0.5517283309937778, 0.36348494895209704],
[0.2938772318522703, 0.2637789775441254, 0.06269729380805578, 0.45950615307641907, 0.6385120155119121],
[0.2513084004763282, 0.43405034274687904, 0.06196354400676052, 0.5172082705599099, 0.5628007410591122],
[0.6594027870204624, 0.7774753303025113, 0.11480777868478287, 0.8282564830110477, 0.6925252855419892],
[0.9411875148018279, 0.9060143983854491, 0.13337488073445947, 0.8512079816569045, 0.9439177644855485],
[0.7843007219438677, 0.8021698575723174, 0.08744386434046159, 0.7706297021961155, 0.8924600863486574],
[0.3843023423570435, 0.3620616596935202, 0.0650781389824251, 0.7174092970635405, 0.415753826806158],
[0.7516223617309036, 0.5534536625909348, 0.07321924378865718, 0.857839302053386, 0.952348936079125],
[0.46297805514871937, 0.453212429342319, 0.07537564277596753, 0.6937903207941987, 0.5000023127896737],
[0.3992318915951315, 0.46404317110536375, 0.06194268722310403, 0.7122378854471726, 0.5336557577463212],
[0.27502009889669665, 0.29401510651370566, 0.059877063363599214, 0.47111061471742477, 0.387595053559872],
[1.1185948746541146, 0.9604948667949674, 0.12471649521170403, 0.815785861385129, 0.9178051493128837],
[0.1780869766018921, 0.19947073837755958, 0.05102234402968797, 0.5578313143659492, 0.39445340520092587],
[0.6487246135086596, 0.6906687474191724, 0.05662931995714959, 0.7646996263181353, 0.920700198985197],
[0.3573545259728438, 0.35087456094042757, 0.03753919866393163, 0.4777346992358813, 0.5042124683730509],
[0.7714593884204661, 0.8714500408188663, 0.1398188687516223, 0.7816739467257361, 0.7453504391635464],
[0.3391538223597893, 0.43312375404574377, 0.06113323134260762, 0.6775203594248048, 0.45016557663374124],
[0.2782794919105336, 0.2531928848362862, 0.0404724411541153, 0.4563987237903442, 0.5078007126376631],
[0.6197283851058603, 0.5784305642409813, 0.11220734690738099, 0.7631149969872837, 0.9051858672743623],
[0.3197023238926828, 0.2592948066102637, 0.0478031121083593, 0.5004934501737455, 0.47067781761382066],
[0.6606281855912237, 0.5849572088923145, 0.07428605672175803, 0.7113898551109327, 0.8501016931392087],
[0.3173910415439104, 0.46536952062699266, 0.05619829322076442, 0.6887901002368371, 0.510655230256106],
[0.5456731513035545, 0.40464024796568854, 0.06197057341618739, 0.7832980664225125, 0.7433477951413217],
[0.2793912270453741, 0.2936910785581811, 0.04049360407514746, 0.33060712283508975, 0.31696720462090067],
[0.4677815214882267, 0.4396269445158737, 0.049497484235242695, 0.7679260035918272, 0.5922246173575445],
[0.24196154318826424, 0.36015225516498683, 0.06063899266066608, 0.684224983235749, 0.5747665009355161],
[0.6105746063983739, 0.7711400144599814, 0.06594075472603711, 0.8383210887364525, 0.8357556355422373],
[0.3146374256224559, 0.4375966244991869, 0.05998052409681465, 0.6697014933652381, 0.5176802958719733],
[0.9792417855808632, 0.8154519047674265, 0.1021260476514464, 0.8980706889078458, 0.9327260485861418],
[0.15612138517916596, 0.17269900067192578, 0.056411188915171606, 0.46727369818531805, 0.4798928931118911],
[0.5212938205411068, 0.4893589850882393, 0.060797594235828534, 0.7772775426584325, 0.5729713978116772],
[0.28670576992842556, 0.3496259520952266, 0.043439550142659655, 0.6076187380962397, 0.5548399502022658],
[0.5314699706745165, 0.5197335987767826, 0.07421365427886428, 0.7084691717887486, 0.6668558703822769],
[0.34125261053014433, 0.4127521714353254, 0.059775766791371865, 0.5230525841856597, 0.46827830066278486],
[0.6462002676213955, 0.6123096331778377, 0.0681627728620865, 0.6972738094237281, 0.851828583565034],
[0.4186680978428001, 0.5536818012168625, 0.07467816352615153, 0.6164684430954124, 0.47303673342814423],
[0.7469548532729888, 0.5502944575830131, 0.09381482262064111, 0.8026514918520554, 1.0441322195127725],
[0.29231511766066665, 0.22838106589912222, 0.06696540160733233, 0.4707526480498401, 0.4335986344258951],
[0.4818956970636554, 0.45470585816745945, 0.04847461471807035, 0.6460029441361217, 0.6246346786693433],
[0.3520385028980899, 0.4716553922790686, 0.06827791129681782, 0.6119708315630605, 0.4997844686476216],
[0.31428927189793554, 0.3803243713999007, 0.05748529160001148, 0.43226730517287915, 0.2826188876922706],
[1.0264997370646944, 1.1350038731338592, 0.10809656702695836, 0.9023749480293822, 0.9712180886432703],
[0.3102623375821013, 0.3797188056043824, 0.04951030639901288, 0.5610251295943369, 0.5258713678603766],
[0.7184627658622569, 0.8145751199268965, 0.09265145791346718, 0.9396161099316196, 0.9894231902391274],
[0.6788136107756824, 0.583770700953258, 0.08090898882054853, 0.7524452744993626, 0.7995439722800987],
[0.2831689579982265, 0.3157640362003096, 0.03597451217849523, 0.459545031158591, 0.3883340448244995],
[0.60275999527731, 0.7056737354324949, 0.05583310189516666, 0.6709807652524394, 0.8541704768569496],
[0.18305902485267744, 0.16195356295030605, 0.035159690423571255, 0.448089036379386, 0.37897414160344745],
[0.5055687857253193, 0.43547300231806074, 0.05374468672470145, 0.6649383743040369, 0.5231191852289601],
[0.3992318915951315, 0.46404317110536375, 0.06194268722310403,0.7122378854471726, 0.5336557577463212],
])


y=np.array([1,1,0,1,0,1,0,1,0,1,1,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,1,1,0,1,0,1,0,1,1,0])

# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=40)

# x_train_new, x_val, y_train_new, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)

# param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}


# model = LogisticRegression()

# grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')

# grid_search.fit(x_train_new, y_train_new)

# best_model = grid_search.best_estimator_

# print("\nBest hyperparameters found by GridSearchCV:", grid_search.best_params_)

# # checking if proper model creation
# print("Logisctic Regression model created successfully!")

# y_pred_val_best = best_model.predict(x_val)

# accuracy_val_best = accuracy_score(y_val, y_pred_val_best)
# print(f"Accuracy on the validation set: {accuracy_val_best:.4f}")

# print("\nClassification Report:")
# print(classification_report(y_val, y_pred_val_best))

# print("\nConfusion Matrix:")
# print(confusion_matrix(y_val, y_pred_val_best))

# # --- Setting a Specific Threshold ---

# # Get the probability of being a 'match' (class 1) for the test set
# y_prob = model.predict_proba(x_val)[:, 1]

# chosen_threshold = 0.4599
# y_pred_tuned = (y_prob >= chosen_threshold).astype(int)

# print(f"\n--- Evaluating with Threshold {chosen_threshold:.2f} ---")

# accuracy_tuned = accuracy_score(y_val, y_pred_tuned)
# print(f"  Accuracy: {accuracy_tuned:.4f}")

# print("  Confusion Matrix:")
# print(confusion_matrix(y_val, y_pred_tuned))

# print("  Classification Report:")
# print(classification_report(y_val, y_pred_tuned, zero_division=0))

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=40)

x_train_new, x_val, y_train_new, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)

param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}

model = LogisticRegression()

grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')

grid_search.fit(x_train_new, y_train_new)

best_model = grid_search.best_estimator_

print("\nBest hyperparameters found by GridSearchCV:", grid_search.best_params_)

# Evaluate the best model on the validation set
y_pred_val_best = best_model.predict(x_val)
accuracy_val_best = accuracy_score(y_val, y_pred_val_best)
print(f"\nAccuracy of the best model on the validation set: {accuracy_val_best:.4f}")
print("\nClassification Report of the best model on the validation set:")
print(classification_report(y_val, y_pred_val_best))
print("\nConfusion Matrix of the best model on the validation set:")
print(confusion_matrix(y_val, y_pred_val_best))

# --- Final Evaluation on Test Set with Best Model ---
print("\n--- Final Evaluation on Test Set with Best Model ---")
y_pred_test_best = best_model.predict(x_test)
accuracy_test_best = accuracy_score(y_test, y_pred_test_best)
print(f"Accuracy on the test set (best model): {accuracy_test_best:.4f}")
print("\nClassification Report on the test set (best model):")
print(classification_report(y_test, y_pred_test_best))
print("\nConfusion Matrix on the test set (best model):")
print(confusion_matrix(y_test, y_pred_test_best))

# --- Evaluating Best Model on Test Set with Threshold ---
y_prob_test_best = best_model.predict_proba(x_test)[:, 1]
chosen_threshold = 0.4599
y_pred_tuned_test_best = (y_prob_test_best >= chosen_threshold).astype(int)

print(f"\n--- Evaluating Best Model on Test Set with Threshold {chosen_threshold:.3f} ---")
accuracy_tuned_test_best = accuracy_score(y_test, y_pred_tuned_test_best)
print(f"  Accuracy on test set: {accuracy_tuned_test_best:.4f}")
print("  Confusion Matrix on test set:")
print(confusion_matrix(y_test, y_pred_tuned_test_best))
print("  Classification Report on test set:")
print(classification_report(y_test, y_pred_tuned_test_best, zero_division=0))




























# y_prob = model.predict_proba(x_test)[:, 1]

# thresholds = np.arange(0.1, 1.0, 0.1)  #Try thresholds from 0.1 to 0.9

# print("\n--- Evaluating with Different Thresholds ---")
# for threshold in thresholds:
#     y_pred_threshold = (y_prob >= threshold).astype(int)

#     accuracy_threshold = accuracy_score(y_test, y_pred_threshold)
#     cm_threshold = confusion_matrix(y_test, y_pred_threshold)
#     report_threshold = classification_report(y_test, y_pred_threshold, zero_division=0) # Handle potential division by zero

#     print(f"\nThreshold: {threshold:.2f}")
#     print(f"  Accuracy: {accuracy_threshold:.4f}")
#     print("  Confusion Matrix:")
#     print(cm_threshold)
#     print("  Classification Report:")
#     print(report_threshold)
